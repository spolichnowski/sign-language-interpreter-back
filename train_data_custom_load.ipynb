{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_data_master.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdCDqiVfRnGk"
      },
      "source": [
        "**Check GPU connection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEgfbCZbRngX"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJMCmfBdRtP8"
      },
      "source": [
        "**Connect to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhuaNjwKRr0R"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC6NIRebRyb8"
      },
      "source": [
        "**Import all required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8Y1cZXzRxTI"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.wrappers.scikit_learn\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop, Rescaling, Resizing\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from utilities import list_paths, create_dataset_and_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXniq6YpR-7C"
      },
      "source": [
        "**Create folder for accuracy/loss charts and model summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fClrdnfeSCRw"
      },
      "source": [
        "print(\"Input training name:\")\n",
        "training_name = input()\n",
        "try:\n",
        "    path = f\"gdrive/MyDrive/BSL/models/{training_name}\"\n",
        "    !mkdir {path}\n",
        "except:\n",
        "    print('Path cannot be created')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq_MZYtxSEkk"
      },
      "source": [
        "**Convolutional Neural Network (CNN) with 4 conv layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFBPU4F4SGyJ"
      },
      "source": [
        "def list_paths(path):\n",
        "    '''\n",
        "    Lists all image paths and labels from a given directory.\n",
        "    '''\n",
        "\n",
        "    images = list()\n",
        "    labels = list()\n",
        "    for name in os.listdir(path):\n",
        "        if name != \".DS_Store\":\n",
        "            labels.append(name)\n",
        "\n",
        "    for label in labels:\n",
        "        full_path = os.path.join(path, label)\n",
        "        for img in os.listdir(full_path):\n",
        "            images.append(os.path.join(full_path, img))\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "def create_dataset_and_labels(images_paths):\n",
        "    ''' \n",
        "    Reads given paths and saves images/labels and puts them into\n",
        "    separate lists\n",
        "    '''\n",
        "\n",
        "    images = list()\n",
        "    labels = list()\n",
        "\n",
        "    for path in images_paths:\n",
        "        try:\n",
        "            image = cv.imread(path)\n",
        "            images.append(image)\n",
        "            labels.append(path.split(os.path.sep)[-2])\n",
        "\n",
        "        except:\n",
        "            print(path + ' not found')\n",
        "            continue\n",
        "\n",
        "    images = np.array(images, dtype=\"float\") / 255.0\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n",
        "\n",
        "def create_accuracy_chart(history, name):\n",
        "    ''' Creates Accuracy chart '''\n",
        "\n",
        "    fig = plt.figure()\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    plt.plot(accuracy)\n",
        "    plt.plot(val_accuracy)\n",
        "    plt.title(\"ACCURACY CHART\")\n",
        "    plt.xlabel('Accuracy')\n",
        "    plt.ylabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.savefig('gdrive/MyDrive/BSL/models/{}/Accuracy'.format(name))\n",
        "\n",
        "\n",
        "def create_loss_chart(history, name):\n",
        "    ''' Creates Loss chart '''\n",
        "\n",
        "    fig = plt.figure()\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    plt.plot(loss)\n",
        "    plt.plot(val_loss)\n",
        "    plt.title(\"LOSS CHART\")\n",
        "    plt.xlabel('Loss')\n",
        "    plt.ylabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.savefig('gdrive/MyDrive/BSL/models/{}/Loss'.format(name))\n",
        "\n",
        "\n",
        "def train(name):\n",
        "    ''' Train model function '''\n",
        "\n",
        "    input_shape = (300, 300, 3)\n",
        "\n",
        "    path = \"../trainingData\"\n",
        "    model_path = \"./model\"\n",
        "    images_paths = list_paths(path)\n",
        "    dataset, labels = create_dataset_and_labels(images_paths)\n",
        "\n",
        "    # Gets training data and create keras train-dataset and test-dataset\n",
        "    (train_x, test_x, train_y, test_y) = train_test_split(\n",
        "        dataset,\n",
        "        labels,\n",
        "        test_size=0.25,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    encoder = LabelEncoder()\n",
        "    train_y = encoder.fit_transform(train_y)\n",
        "    test_y = encoder.fit_transform(test_y)\n",
        "\n",
        "    # Data augmentation flips randomly input and rotates it by 0.3\n",
        "    data_augmentation = keras.Sequential([\n",
        "        layers.experimental.preprocessing.RandomFlip(\n",
        "            \"horizontal_and_vertical\"),\n",
        "        layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    ])\n",
        "\n",
        "    # Resizes data to (180, 180) and rescales it to be between 0 and 1 \n",
        "    data_resize = keras.Sequential([\n",
        "        Resizing(180, 180)\n",
        "        # Rescaling(1./255)\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Begining of the model\n",
        "    # Input layer reshapes input to be compatibile\n",
        "\n",
        "    # Augmentation resizing and rescaling\n",
        "    x = data_resize(inputs)\n",
        "    x = data_augmentation(x)\n",
        "\n",
        "    # Convolutional layer 1\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Convolutional layer 2\n",
        "    x = layers.Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Convolutional layer 3\n",
        "    x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Convolutional layer 4\n",
        "    x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Dropout to prevent overfitting\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Flatten (batch, num)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    # Dense layer with relu activation\n",
        "    x = layers.Dense(512, activation=\"relu\")(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Creates and saves model summary as an image\n",
        "    plot_model(\n",
        "        model,\n",
        "        to_file='./models/{}/model_summary.png'.format(name),\n",
        "        show_layer_names=True,\n",
        "        show_shapes=True\n",
        "    )\n",
        "\n",
        "    # Displays model summary in terminal\n",
        "    model.summary()\n",
        "\n",
        "    # Sets loss and optomazer algoriths\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Trains the model and saves it do history variable\n",
        "    history = model.fit(train_x, train_y, batch_size=32,\n",
        "                        epochs=32, validation_data=(test_x, test_y))\n",
        "\n",
        "    # Create loss and accuracy functions\n",
        "    create_accuracy_chart(history, name)\n",
        "    create_loss_chart(history, name)\n",
        "\n",
        "    # Saves model\n",
        "    keras.models.save_model(\n",
        "        model,\n",
        "        model_path,\n",
        "        overwrite=True,\n",
        "        include_optimizer=True,\n",
        "        save_format=None,\n",
        "        signatures=None,\n",
        "        options=None,\n",
        "    )\n",
        "\n",
        "\n",
        "train(training_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}