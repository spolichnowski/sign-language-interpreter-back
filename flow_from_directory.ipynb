{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flow_from_directory.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zboxb4mNa1ct"
      },
      "source": [
        "**Check GPU connection**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h08oO-JO01I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67dfac05-d436-4ad5-c3ee-dd271f5f5cc1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr 30 00:15:47 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9r2R61zUg7s"
      },
      "source": [
        "**Connect to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3IV3eInRFE9"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1zPie78Ua1F"
      },
      "source": [
        "**Import all required libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQAvnBLlRF-2"
      },
      "source": [
        "import random\n",
        "import time\n",
        "import tensorflow\n",
        "import datetime\n",
        "import sklearn\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop, Rescaling, Resizing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from cv2 import cv2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7n72wpRbCE1"
      },
      "source": [
        "**Create folder for accuracy/loss charts and model summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASkm-g8EWSck"
      },
      "source": [
        "print(\"Input training name:\")\n",
        "training_name = input()\n",
        "try:\n",
        "    path = f\"gdrive/MyDrive/BSL/models/{training_name}\"\n",
        "    !mkdir {path}\n",
        "except:\n",
        "    print('Path cannot be created')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ksiO8GhG9_K"
      },
      "source": [
        "training_name = \"test\" #\"FINAL_BASE_MODEL\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX1D3VycAAeQ"
      },
      "source": [
        "**Convolutional Neural Network (CNN) with 4 conv layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAn1KXE6UltX"
      },
      "source": [
        "def train(name):\n",
        "    ''' Train model function '''\n",
        "\n",
        "    batch_size = 32\n",
        "    TRAIN_PATH = \"gdrive/MyDrive/BSL/FINAL_DATASET_300x300/\"\n",
        "    TEST_PATH = \"gdrive/MyDrive/BSL/TEST_FINAL/\"\n",
        "    model_path = \"gdrive/MyDrive/BSL/models/{}/\".format(name)\n",
        "\n",
        "    # Sets preprocessing for training images\n",
        "    train_pip = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        horizontal_flip=True,\n",
        "        brightness_range=[0.2, 1.0],\n",
        "        rotation_range=20,\n",
        "      )\n",
        "\n",
        "    # Sets preprocessing for test images\n",
        "    val_ds_pip = ImageDataGenerator(\n",
        "        rescale=1./255\n",
        "      )\n",
        "\n",
        "    # Creates train dataset\n",
        "    train_ds = train_pip.flow_from_directory(\n",
        "        TRAIN_PATH,\n",
        "        target_size = (300, 300),\n",
        "        batch_size=32,\n",
        "        seed=1337,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    # Creates test dataset\n",
        "    val_ds = val_ds_pip.flow_from_directory(\n",
        "        TEST_PATH,\n",
        "        target_size = (300, 300),\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    # Begining of the model\n",
        "\n",
        "    # Input layer reshapes input to be compatibile\n",
        "    inputs = keras.Input(shape=(300, 300)+(3,))\n",
        "\n",
        "    # Convolutional layer 1\n",
        "    x = layers.Conv2D(128, (3, 3), padding='same', activation=\"relu\")(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Convolutional layer 2\n",
        "    x = layers.Conv2D(128, (3, 3), activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Convolutional layer 3\n",
        "    x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Convolutional layer 4\n",
        "    x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Dropout to prevent overfitting\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Flatten (batch, num)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    # Dense layer with relu activation\n",
        "    x = layers.Dense(512, activation=\"relu\")(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Dense(17, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Creates and saves model summary as an image\n",
        "    plot_model(\n",
        "        model,\n",
        "        to_file=model_path + 'model_summary.png',\n",
        "        show_layer_names=True,\n",
        "        show_shapes=True\n",
        "    )\n",
        "\n",
        "    # Displays model summary in terminal\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "    # Sets loss and optomazer algoriths\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Tensorboard\n",
        "    log_dir = model_path + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "    # Trains the model and saves it do history variable\n",
        "    history = model.fit(train_ds, batch_size=batch_size,\n",
        "                        epochs=96, validation_data=val_ds, callbacks=[tensorboard_callback])\n",
        "\n",
        "    # Evaluate\n",
        "    model.evaluate(val_ds, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    # Saves model\n",
        "    keras.models.save_model(\n",
        "        model,\n",
        "        model_path,\n",
        "        overwrite=True,\n",
        "        include_optimizer=True,\n",
        "        save_format=None,\n",
        "        signatures=None,\n",
        "        options=None,\n",
        "    )\n",
        "\n",
        "\n",
        "train(training_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}